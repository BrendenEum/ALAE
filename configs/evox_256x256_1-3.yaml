 # Config for training ALAE on evox at resolution 256x256

NAME: evox_256x256_1-3
DATASET:
  PART_COUNT: 1 # how many times to split up the dataset (for parallelizing?)
  SIZE: 34861
  PATH: /home/beum/scratch/ALAE/data/datasets/evox_256x256_1-3/evox_256x256_1-3-r%02d.tfrecords.%03d
  PATH_TEST: /home/beum/scratch/ALAE/data/datasets/evox-test_256x256_1-3/evox-test_256x256_1-3-r%02d.tfrecords.%03d
  MAX_RESOLUTION_LEVEL: 8

  SAMPLES_PATH: no_path #dataset_samples/cars
  STYLE_MIX_PATH: style_mixing/test_images/set_cars
MODEL:
  LATENT_SPACE_SIZE: 512
  LAYER_COUNT: 8
  MAX_CHANNEL_COUNT: 512
  START_CHANNEL_COUNT: 32
  DLATENT_AVG_BETA: 0.995
  MAPPING_LAYERS: 8
  CHANNELS: 1 #greyscale
OUTPUT_DIR: training_artifacts/evox_256x256_1-3
TRAIN:
  BASE_LEARNING_RATE: 0.002
  EPOCHS_PER_LOD: 2
  LEARNING_DECAY_RATE: 0.1
  LEARNING_DECAY_STEPS: []
  TRAIN_EPOCHS: 112
  #                  4    8    16   32  64  128 256
  LOD_2_BATCH_1GPU: [32, 32, 32, 32, 16, 16, 16]
  LOD_2_BATCH_2GPU: [32, 32, 32, 32, 16, 16, 16]
  LOD_2_BATCH_4GPU: [32, 32, 32, 32, 16, 16, 16]
  LOD_2_BATCH_8GPU: [32, 32, 32, 32, 16, 16, 16]
  #LOD_2_BATCH_1GPU: [512, 256, 128, 64, 32, 32, 16]
  #LOD_2_BATCH_2GPU: [512, 256, 128, 64, 32, 32, 32]
  #LOD_2_BATCH_4GPU: [512, 256, 128, 64, 32, 32, 32, 32, 32]
  #LOD_2_BATCH_8GPU: [512, 256, 128, 64, 32, 32, 32, 32, 32]

  LEARNING_RATES: [.0015, .0015, .0015, .0015, .0015, .0015, .002, .003, .003]
